{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8d604e-33c5-4fa2-a0fb-4b1048c3513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SVM (RBF) Feature Selection ---\n",
      "Selected features: ['Feature_avg_centroid_frequency_Power_Spectrum_Density_ML', 'Feature_asym_peak_velocity_pos_SPD_ML', 'Feature_avg_peak_velocity_all_SPD_ML', 'Sex_Male']\n",
      "=== SVM (RBF) ===\n",
      "Best params: {'clf__C': 1, 'clf__gamma': 'scale'}\n",
      "Accuracy : 0.757 ± 0.076\n",
      "Precision: 0.740 ± 0.114\n",
      "Recall   : 0.734 ± 0.078\n",
      "F1-score : 0.734 ± 0.086\n",
      "ROC-AUC  : 0.755 ± 0.082\n",
      "\n",
      "--- Random Forest Feature Selection ---\n",
      "Selected features: ['Feature_asym_range_ML', 'Feature_avg_frequency_mode_Power_Spectrum_Density_ML', 'Feature_asym_confidence_ellipse_area_ML_AND_AP', 'Feature_asym_mean_distance_AP', 'Feature_avg_centroid_frequency_Power_Spectrum_Density_ML']\n",
      "=== Random Forest ===\n",
      "Best params: {'clf__max_depth': None, 'clf__n_estimators': 100}\n",
      "Accuracy : 0.730 ± 0.089\n",
      "Precision: 0.736 ± 0.158\n",
      "Recall   : 0.695 ± 0.145\n",
      "F1-score : 0.699 ± 0.103\n",
      "ROC-AUC  : 0.755 ± 0.103\n",
      "\n",
      "--- Logistic Regression Feature Selection ---\n",
      "Selected features: ['Sex_Male', 'Feature_asym_long_time_scaling_Diffusion_ML', 'Feature_avg_mean_frequency_AP', 'Feature_avg_maximal_distance_Radius', 'Feature_avg_energy_content_05_2_Power_Spectrum_Density_AP', 'Feature_avg_critical_time_Diffusion_AP', 'Feature_avg_peak_velocity_pos_SPD_AP']\n",
      "=== Logistic Regression ===\n",
      "Best params: {'clf__C': 1}\n",
      "Accuracy : 0.774 ± 0.084\n",
      "Precision: 0.793 ± 0.142\n",
      "Recall   : 0.694 ± 0.120\n",
      "F1-score : 0.735 ± 0.109\n",
      "ROC-AUC  : 0.707 ± 0.150\n",
      "\n",
      "--- k-NN Feature Selection ---\n",
      "Selected features: ['Feature_avg_centroid_frequency_Power_Spectrum_Density_ML', 'Feature_avg_short_time_diffusion_Diffusion_ML', 'Feature_avg_long_time_diffusion_Diffusion_ML', 'Feature_asym_critical_displacement_Diffusion_ML', 'Feature_avg_critical_displacement_Diffusion_ML']\n",
      "=== k-NN ===\n",
      "Best params: {'clf__n_neighbors': 5}\n",
      "Accuracy : 0.765 ± 0.081\n",
      "Precision: 0.753 ± 0.105\n",
      "Recall   : 0.755 ± 0.040\n",
      "F1-score : 0.752 ± 0.071\n",
      "ROC-AUC  : 0.737 ± 0.103\n",
      "\n",
      "--- Gaussian NB Feature Selection ---\n",
      "Selected features: ['Feature_avg_frequency_quotient_Power_Spectrum_Density_AP', 'Feature_avg_critical_displacement_Diffusion_ML', 'Feature_avg_frequency_quotient_Power_Spectrum_Density_ML', 'Feature_asym_maximal_distance_Radius']\n",
      "=== Gaussian NB ===\n",
      "Best params: {}\n",
      "Accuracy : 0.652 ± 0.113\n",
      "Precision: 0.588 ± 0.101\n",
      "Recall   : 0.940 ± 0.049\n",
      "F1-score : 0.718 ± 0.077\n",
      "ROC-AUC  : 0.644 ± 0.125\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# --- Load data ---\n",
    "con_df = pd.read_csv(r\"E:\\USA_PD_2024\\Analysis\\ppr6\\COP\\Data\\Walk\\Full\\Controlled.csv\")\n",
    "pd_df = pd.read_csv(r\"E:\\USA_PD_2024\\Analysis\\ppr6\\COP\\Data\\Walk\\Full\\PD.csv\")\n",
    "\n",
    "con_df[\"label\"] = 0\n",
    "pd_df[\"label\"] = 1\n",
    "df = pd.concat([con_df, pd_df], ignore_index=True)\n",
    "\n",
    "# --- Extract SubjectID from File name ---\n",
    "def get_id(fname):\n",
    "    base = Path(fname).stem\n",
    "    m = re.search(r\"_[a-zA-Z]*([0-9]+)\", base)\n",
    "    return m.group(1) if m else base\n",
    "\n",
    "df[\"SubjectID\"] = df[\"File\"].apply(get_id)\n",
    "\n",
    "# --- Drop non-feature columns: label, File, SubjectID, and Age ---\n",
    "X = df.drop(columns=[\"label\", \"File\", \"SubjectID\", \"Age\"])\n",
    "X = pd.get_dummies(X, columns=[\"Sex\"], drop_first=True)\n",
    "y = df[\"label\"].values\n",
    "groups = df[\"SubjectID\"].values\n",
    "\n",
    "# --- Cross-validation setup ---\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# --- Forward Selection based on F1-score ---\n",
    "def groupwise_sfs(pipe, X, y, groups):\n",
    "    best_score = 0\n",
    "    selected = []\n",
    "    remaining = list(X.columns)\n",
    "    while remaining:\n",
    "        best_feat = None\n",
    "        for feat in remaining:\n",
    "            trial_feats = selected + [feat]\n",
    "            fold_scores = []\n",
    "            for tr, te in cv.split(X[trial_feats], y, groups):\n",
    "                model = clone(pipe)\n",
    "                model.fit(X[trial_feats].iloc[tr], y[tr])\n",
    "                preds = model.predict(X[trial_feats].iloc[te])\n",
    "                fold_scores.append(f1_score(y[te], preds))\n",
    "            mean_score = np.mean(fold_scores)\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_feat = feat\n",
    "        if best_feat:\n",
    "            selected.append(best_feat)\n",
    "            remaining.remove(best_feat)\n",
    "        else:\n",
    "            break\n",
    "    return selected\n",
    "\n",
    "# --- Define models and hyperparameters ---\n",
    "models = [\n",
    "    (\"SVM (RBF)\", Pipeline([(\"scaler\", StandardScaler()), (\"clf\", SVC(kernel=\"rbf\", probability=True, random_state=42))]),\n",
    "     {\"clf__C\": [0.1, 1, 10], \"clf__gamma\": [\"scale\", 0.1]}),\n",
    "\n",
    "    (\"Random Forest\", Pipeline([(\"clf\", RandomForestClassifier(random_state=42, n_jobs=-1))]),\n",
    "     {\"clf__n_estimators\": [100], \"clf__max_depth\": [None]}),\n",
    "\n",
    "    (\"Logistic Regression\", Pipeline([(\"scaler\", StandardScaler()), (\"clf\", LogisticRegression(max_iter=500, random_state=42))]),\n",
    "     {\"clf__C\": [1]}),\n",
    "\n",
    "    (\"k-NN\", Pipeline([(\"scaler\", StandardScaler()), (\"clf\", KNeighborsClassifier())]),\n",
    "     {\"clf__n_neighbors\": [5, 7]}),\n",
    "\n",
    "    (\"Gaussian NB\", Pipeline([(\"clf\", GaussianNB())]),\n",
    "     {})\n",
    "]\n",
    "\n",
    "# --- Train and Evaluate each model ---\n",
    "for name, pipe, param_grid in models:\n",
    "    print(f\"\\n--- {name} Feature Selection ---\")\n",
    "    selected_feats = groupwise_sfs(pipe, X, y, groups)\n",
    "    print(f\"Selected features: {selected_feats}\")\n",
    "\n",
    "    X_sel = X[selected_feats]\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    gs = GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1)\n",
    "    gs.fit(X_sel, y, groups=groups)\n",
    "    best_est = gs.best_estimator_\n",
    "\n",
    "    # Evaluation with best estimator\n",
    "    accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "    for tr, te in cv.split(X_sel, y, groups):\n",
    "        best_est.fit(X_sel.iloc[tr], y[tr])\n",
    "        preds = best_est.predict(X_sel.iloc[te])\n",
    "        probs = (best_est.predict_proba(X_sel.iloc[te])[:, 1]\n",
    "                 if hasattr(best_est, \"predict_proba\")\n",
    "                 else best_est.decision_function(X_sel.iloc[te]))\n",
    "\n",
    "        accs.append(accuracy_score(y[te], preds))\n",
    "        precs.append(precision_score(y[te], preds))\n",
    "        recs.append(recall_score(y[te], preds))\n",
    "        f1s.append(f1_score(y[te], preds))\n",
    "        aucs.append(roc_auc_score(y[te], probs))\n",
    "\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(f\"Best params: {gs.best_params_}\")\n",
    "    print(f\"Accuracy : {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n",
    "    print(f\"Precision: {np.mean(precs):.3f} ± {np.std(precs):.3f}\")\n",
    "    print(f\"Recall   : {np.mean(recs):.3f} ± {np.std(recs):.3f}\")\n",
    "    print(f\"F1-score : {np.mean(f1s):.3f} ± {np.std(f1s):.3f}\")\n",
    "    print(f\"ROC-AUC  : {np.mean(aucs):.3f} ± {np.std(aucs):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09822fca-3751-45d1-b413-16fd3bb68d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
