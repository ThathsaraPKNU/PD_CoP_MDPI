{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763b98cc-d90f-4dbf-bd5c-c5913a9a20ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All selected features are present.\n",
      "\n",
      "ğŸ”¹ SVM (RBF) Model ğŸ”¹\n",
      "Best Params: {'clf__C': 1, 'clf__gamma': 0.1}\n",
      "Accuracy : 0.870 Â± 0.095\n",
      "Precision: 0.887 Â± 0.153\n",
      "Recall   : 0.852 Â± 0.065\n",
      "F1-score : 0.862 Â± 0.093\n",
      "ROC-AUC  : 0.881 Â± 0.082\n",
      "\n",
      "ğŸ”¹ Random Forest Model ğŸ”¹\n",
      "Best Params: {'clf__max_depth': None, 'clf__n_estimators': 100}\n",
      "Accuracy : 0.835 Â± 0.101\n",
      "Precision: 0.836 Â± 0.164\n",
      "Recall   : 0.832 Â± 0.062\n",
      "F1-score : 0.826 Â± 0.099\n",
      "ROC-AUC  : 0.862 Â± 0.116\n",
      "\n",
      "ğŸ”¹ Logistic Regression Model ğŸ”¹\n",
      "Best Params: {'clf__C': 1}\n",
      "Accuracy : 0.774 Â± 0.084\n",
      "Precision: 0.788 Â± 0.135\n",
      "Recall   : 0.739 Â± 0.083\n",
      "F1-score : 0.753 Â± 0.075\n",
      "ROC-AUC  : 0.827 Â± 0.102\n",
      "\n",
      "ğŸ”¹ k-NN Model ğŸ”¹\n",
      "Best Params: {'clf__n_neighbors': 7}\n",
      "Accuracy : 0.852 Â± 0.081\n",
      "Precision: 0.877 Â± 0.158\n",
      "Recall   : 0.834 Â± 0.086\n",
      "F1-score : 0.842 Â± 0.075\n",
      "ROC-AUC  : 0.873 Â± 0.101\n",
      "\n",
      "ğŸ”¹ Gaussian NB Model ğŸ”¹\n",
      "Best Params: {}\n",
      "Accuracy : 0.809 Â± 0.081\n",
      "Precision: 0.797 Â± 0.141\n",
      "Recall   : 0.832 Â± 0.109\n",
      "F1-score : 0.801 Â± 0.074\n",
      "ROC-AUC  : 0.874 Â± 0.106\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Binary PD vs Control classification using manually selected CoP + demographic features\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Features: 15 CoP-derived + Height, Weight, Sex (if available)\n",
    "Modeling: SVM, RF, LR, k-NN, GNB\n",
    "Validation: 5-fold GroupKFold using SubjectID\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. Imports\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. Load and concatenate data\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "con_df = pd.read_csv(r\"E:\\USA_PD_2024\\Analysis\\ppr6\\COP\\Data\\Combine_Activity\\Full\\Controlled1.csv\")\n",
    "pd_df  = pd.read_csv(r\"E:\\USA_PD_2024\\Analysis\\ppr6\\COP\\Data\\Combine_Activity\\Full\\PD1.csv\")\n",
    "\n",
    "con_df[\"label\"] = 0\n",
    "pd_df [\"label\"] = 1\n",
    "df = pd.concat([con_df, pd_df], ignore_index=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. Clean column names\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df.columns = df.columns.str.strip().str.replace(\" \", \"_\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4. Extract Subject ID from filename\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_id(fname: str) -> str:\n",
    "    base = Path(fname).stem\n",
    "    m = re.search(r\"_[a-zA-Z]*([0-9]+)\", base)\n",
    "    return m.group(1) if m else base\n",
    "\n",
    "df[\"SubjectID\"] = df[\"File\"].apply(get_id)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5. Manually selected features\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "manual_features = [\n",
    "    \"Feature_asym_energy_content_below_05_Power_Spectrum_Density_AP\",\n",
    "    \"Feature_avg_frequency_quotient_Power_Spectrum_Density_ML\",\n",
    "    \"Feature_avg_fractal_dimension_ML_AND_AP\",\n",
    "    \"Feature_avg_phase_plane_parameter_ML\",\n",
    "    \"Feature_avg_short_time_diffusion_Diffusion_ML\",\n",
    "    \"Feature_asym_mean_distance_Radius\",\n",
    "    \"Height\"\n",
    "]\n",
    "\n",
    "# Check availability\n",
    "available_features = [f for f in manual_features if f in df.columns]\n",
    "missing = set(manual_features) - set(available_features)\n",
    "if missing:\n",
    "    print(f\"âš ï¸ Warning: Missing features skipped: {missing}\")\n",
    "else:\n",
    "    print(\"âœ… All selected features are present.\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 6. Prepare feature matrix X\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if \"Sex\" in df.columns:\n",
    "    X = df[available_features + [\"Sex\"]].copy()\n",
    "    X = pd.get_dummies(X, columns=[\"Sex\"], drop_first=True)\n",
    "else:\n",
    "    X = df[available_features].copy()\n",
    "    print(\"âš ï¸ 'Sex' column not found. Proceeding without it.\")\n",
    "\n",
    "y = df[\"label\"].values\n",
    "groups = df[\"SubjectID\"].values\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 7. Cross-validation setup\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 8. Models and parameter grids\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "models = [\n",
    "    (\"SVM (RBF)\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(kernel=\"rbf\", probability=True, random_state=42))\n",
    "    ]), {\"clf__C\": [0.1, 1, 10], \"clf__gamma\": [\"scale\", 0.1]}),\n",
    "\n",
    "    (\"Random Forest\", Pipeline([\n",
    "        (\"clf\", RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "    ]), {\"clf__n_estimators\": [100], \"clf__max_depth\": [None]}),\n",
    "\n",
    "    (\"Logistic Regression\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=500, random_state=42))\n",
    "    ]), {\"clf__C\": [1]}),\n",
    "\n",
    "    (\"k-NN\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier())\n",
    "    ]), {\"clf__n_neighbors\": [5, 7]}),\n",
    "\n",
    "    (\"Gaussian NB\", Pipeline([\n",
    "        (\"clf\", GaussianNB())\n",
    "    ]), {})\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 9. Train, tune and evaluate\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for name, pipe, param_grid in models:\n",
    "    print(f\"\\nğŸ”¹ {name} Model ğŸ”¹\")\n",
    "    \n",
    "    # Grid Search CV\n",
    "    gs = GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1)\n",
    "    gs.fit(X, y, groups=groups)\n",
    "    best_est = gs.best_estimator_\n",
    "\n",
    "    # Evaluate with group-wise CV\n",
    "    accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "    for tr, te in cv.split(X, y, groups):\n",
    "        best_est.fit(X.iloc[tr], y[tr])\n",
    "        preds = best_est.predict(X.iloc[te])\n",
    "        probs = (best_est.predict_proba(X.iloc[te])[:, 1]\n",
    "                 if hasattr(best_est, \"predict_proba\")\n",
    "                 else best_est.decision_function(X.iloc[te]))\n",
    "\n",
    "        accs.append(accuracy_score(y[te], preds))\n",
    "        precs.append(precision_score(y[te], preds, zero_division=0))\n",
    "        recs.append(recall_score(y[te], preds, zero_division=0))\n",
    "        f1s.append(f1_score(y[te], preds, zero_division=0))\n",
    "        aucs.append(roc_auc_score(y[te], probs))\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Best Params: {gs.best_params_}\")\n",
    "    print(f\"Accuracy : {np.mean(accs):.3f} Â± {np.std(accs):.3f}\")\n",
    "    print(f\"Precision: {np.mean(precs):.3f} Â± {np.std(precs):.3f}\")\n",
    "    print(f\"Recall   : {np.mean(recs):.3f} Â± {np.std(recs):.3f}\")\n",
    "    print(f\"F1-score : {np.mean(f1s):.3f} Â± {np.std(f1s):.3f}\")\n",
    "    print(f\"ROC-AUC  : {np.mean(aucs):.3f} Â± {np.std(aucs):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597b13e9-681e-4f4e-a527-02004565e7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All selected features are present.\n",
      "\n",
      "ğŸ”¹ SVM (RBF) Model ğŸ”¹\n",
      "Best Params: {'clf__C': 1, 'clf__gamma': 'scale'}\n",
      "Accuracy : 0.852 Â± 0.076\n",
      "Precision: 0.883 Â± 0.145\n",
      "Recall   : 0.817 Â± 0.086\n",
      "F1-score : 0.839 Â± 0.077\n",
      "ROC-AUC  : 0.894 Â± 0.088\n",
      "\n",
      "ğŸ”¹ Random Forest Model ğŸ”¹\n",
      "Best Params: {'clf__max_depth': None, 'clf__n_estimators': 100}\n",
      "Accuracy : 0.817 Â± 0.111\n",
      "Precision: 0.829 Â± 0.178\n",
      "Recall   : 0.815 Â± 0.088\n",
      "F1-score : 0.810 Â± 0.106\n",
      "ROC-AUC  : 0.852 Â± 0.127\n",
      "\n",
      "ğŸ”¹ Logistic Regression Model ğŸ”¹\n",
      "Best Params: {'clf__C': 1}\n",
      "Accuracy : 0.765 Â± 0.081\n",
      "Precision: 0.777 Â± 0.141\n",
      "Recall   : 0.739 Â± 0.083\n",
      "F1-score : 0.746 Â± 0.070\n",
      "ROC-AUC  : 0.845 Â± 0.089\n",
      "\n",
      "ğŸ”¹ k-NN Model ğŸ”¹\n",
      "Best Params: {'clf__n_neighbors': 5}\n",
      "Accuracy : 0.852 Â± 0.105\n",
      "Precision: 0.868 Â± 0.173\n",
      "Recall   : 0.854 Â± 0.088\n",
      "F1-score : 0.848 Â± 0.096\n",
      "ROC-AUC  : 0.871 Â± 0.108\n",
      "\n",
      "ğŸ”¹ Gaussian NB Model ğŸ”¹\n",
      "Best Params: {}\n",
      "Accuracy : 0.817 Â± 0.127\n",
      "Precision: 0.821 Â± 0.184\n",
      "Recall   : 0.848 Â± 0.101\n",
      "F1-score : 0.817 Â± 0.105\n",
      "ROC-AUC  : 0.876 Â± 0.097\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Binary PD vs Control classification using manually selected CoP + demographic features\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Features: 15 CoP-derived + Height, Weight, Sex (if available)\n",
    "Modeling: SVM, RF, LR, k-NN, GNB\n",
    "Validation: 5-fold GroupKFold using SubjectID\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. Imports\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. Load and concatenate data\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "con_df = pd.read_csv(r\"E:\\USA_PD_2024\\Analysis\\ppr6\\COP\\Data\\Combine_Activity\\Full\\Controlled1.csv\")\n",
    "pd_df  = pd.read_csv(r\"E:\\USA_PD_2024\\Analysis\\ppr6\\COP\\Data\\Combine_Activity\\Full\\PD1.csv\")\n",
    "\n",
    "con_df[\"label\"] = 0\n",
    "pd_df [\"label\"] = 1\n",
    "df = pd.concat([con_df, pd_df], ignore_index=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. Clean column names\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df.columns = df.columns.str.strip().str.replace(\" \", \"_\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4. Extract Subject ID from filename\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_id(fname: str) -> str:\n",
    "    base = Path(fname).stem\n",
    "    m = re.search(r\"_[a-zA-Z]*([0-9]+)\", base)\n",
    "    return m.group(1) if m else base\n",
    "\n",
    "df[\"SubjectID\"] = df[\"File\"].apply(get_id)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5. Manually selected features\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "manual_features = [\n",
    "    \"Feature_asym_energy_content_below_05_Power_Spectrum_Density_AP\",\n",
    "    \"Feature_avg_frequency_quotient_Power_Spectrum_Density_ML\",\n",
    "    \"Feature_avg_fractal_dimension_ML_AND_AP\",\n",
    "    \"Feature_avg_phase_plane_parameter_ML\",\n",
    "    \"Feature_avg_short_time_diffusion_Diffusion_ML\",\n",
    "    \"Feature_asym_mean_distance_Radius\"\n",
    "]\n",
    "\n",
    "# Check availability\n",
    "available_features = [f for f in manual_features if f in df.columns]\n",
    "missing = set(manual_features) - set(available_features)\n",
    "if missing:\n",
    "    print(f\"âš ï¸ Warning: Missing features skipped: {missing}\")\n",
    "else:\n",
    "    print(\"âœ… All selected features are present.\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 6. Prepare feature matrix X\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if \"Sex\" in df.columns:\n",
    "    X = df[available_features + [\"Sex\"]].copy()\n",
    "    X = pd.get_dummies(X, columns=[\"Sex\"], drop_first=True)\n",
    "else:\n",
    "    X = df[available_features].copy()\n",
    "    print(\"âš ï¸ 'Sex' column not found. Proceeding without it.\")\n",
    "\n",
    "y = df[\"label\"].values\n",
    "groups = df[\"SubjectID\"].values\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 7. Cross-validation setup\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 8. Models and parameter grids\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "models = [\n",
    "    (\"SVM (RBF)\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(kernel=\"rbf\", probability=True, random_state=42))\n",
    "    ]), {\"clf__C\": [0.1, 1, 10], \"clf__gamma\": [\"scale\", 0.1]}),\n",
    "\n",
    "    (\"Random Forest\", Pipeline([\n",
    "        (\"clf\", RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "    ]), {\"clf__n_estimators\": [100], \"clf__max_depth\": [None]}),\n",
    "\n",
    "    (\"Logistic Regression\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=500, random_state=42))\n",
    "    ]), {\"clf__C\": [1]}),\n",
    "\n",
    "    (\"k-NN\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier())\n",
    "    ]), {\"clf__n_neighbors\": [5, 7]}),\n",
    "\n",
    "    (\"Gaussian NB\", Pipeline([\n",
    "        (\"clf\", GaussianNB())\n",
    "    ]), {})\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 9. Train, tune and evaluate\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for name, pipe, param_grid in models:\n",
    "    print(f\"\\nğŸ”¹ {name} Model ğŸ”¹\")\n",
    "    \n",
    "    # Grid Search CV\n",
    "    gs = GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1)\n",
    "    gs.fit(X, y, groups=groups)\n",
    "    best_est = gs.best_estimator_\n",
    "\n",
    "    # Evaluate with group-wise CV\n",
    "    accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "    for tr, te in cv.split(X, y, groups):\n",
    "        best_est.fit(X.iloc[tr], y[tr])\n",
    "        preds = best_est.predict(X.iloc[te])\n",
    "        probs = (best_est.predict_proba(X.iloc[te])[:, 1]\n",
    "                 if hasattr(best_est, \"predict_proba\")\n",
    "                 else best_est.decision_function(X.iloc[te]))\n",
    "\n",
    "        accs.append(accuracy_score(y[te], preds))\n",
    "        precs.append(precision_score(y[te], preds, zero_division=0))\n",
    "        recs.append(recall_score(y[te], preds, zero_division=0))\n",
    "        f1s.append(f1_score(y[te], preds, zero_division=0))\n",
    "        aucs.append(roc_auc_score(y[te], probs))\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Best Params: {gs.best_params_}\")\n",
    "    print(f\"Accuracy : {np.mean(accs):.3f} Â± {np.std(accs):.3f}\")\n",
    "    print(f\"Precision: {np.mean(precs):.3f} Â± {np.std(precs):.3f}\")\n",
    "    print(f\"Recall   : {np.mean(recs):.3f} Â± {np.std(recs):.3f}\")\n",
    "    print(f\"F1-score : {np.mean(f1s):.3f} Â± {np.std(f1s):.3f}\")\n",
    "    print(f\"ROC-AUC  : {np.mean(aucs):.3f} Â± {np.std(aucs):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a6ca574-baa3-4a74-809c-2614f00a0e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All selected features are present.\n",
      "\n",
      "ğŸ”¹ SVM (RBF) Model ğŸ”¹\n",
      "Best Params: {'clf__C': 1, 'clf__gamma': 'scale'}\n",
      "Accuracy : 0.870 Â± 0.055\n",
      "Precision: 0.888 Â± 0.138\n",
      "Recall   : 0.850 Â± 0.042\n",
      "F1-score : 0.860 Â± 0.050\n",
      "ROC-AUC  : 0.928 Â± 0.050\n",
      "\n",
      "ğŸ”¹ Random Forest Model ğŸ”¹\n",
      "Best Params: {'clf__max_depth': None, 'clf__n_estimators': 100}\n",
      "Accuracy : 0.809 Â± 0.044\n",
      "Precision: 0.825 Â± 0.135\n",
      "Recall   : 0.795 Â± 0.087\n",
      "F1-score : 0.795 Â± 0.027\n",
      "ROC-AUC  : 0.897 Â± 0.048\n",
      "\n",
      "ğŸ”¹ Logistic Regression Model ğŸ”¹\n",
      "Best Params: {'clf__C': 1}\n",
      "Accuracy : 0.791 Â± 0.051\n",
      "Precision: 0.794 Â± 0.118\n",
      "Recall   : 0.779 Â± 0.079\n",
      "F1-score : 0.776 Â± 0.040\n",
      "ROC-AUC  : 0.871 Â± 0.067\n",
      "\n",
      "ğŸ”¹ k-NN Model ğŸ”¹\n",
      "Best Params: {'clf__n_neighbors': 5}\n",
      "Accuracy : 0.809 Â± 0.071\n",
      "Precision: 0.806 Â± 0.111\n",
      "Recall   : 0.792 Â± 0.113\n",
      "F1-score : 0.789 Â± 0.080\n",
      "ROC-AUC  : 0.872 Â± 0.040\n",
      "\n",
      "ğŸ”¹ Gaussian NB Model ğŸ”¹\n",
      "Best Params: {}\n",
      "Accuracy : 0.800 Â± 0.059\n",
      "Precision: 0.799 Â± 0.137\n",
      "Recall   : 0.795 Â± 0.059\n",
      "F1-score : 0.787 Â± 0.052\n",
      "ROC-AUC  : 0.881 Â± 0.058\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Binary PD vs Control classification using manually selected CoP + demographic features\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Features: 15 CoP-derived + Height, Weight, Sex (if available)\n",
    "Modeling: SVM, RF, LR, k-NN, GNB\n",
    "Validation: 5-fold GroupKFold using SubjectID\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. Imports\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. Load and concatenate data\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "con_df = pd.read_csv(r\"E:\\USA_PD_2024\\Analysis\\ppr6\\COP\\Data\\Combine_Activity\\Full\\Controlled1.csv\")\n",
    "pd_df  = pd.read_csv(r\"E:\\USA_PD_2024\\Analysis\\ppr6\\COP\\Data\\Combine_Activity\\Full\\PD1.csv\")\n",
    "\n",
    "con_df[\"label\"] = 0\n",
    "pd_df [\"label\"] = 1\n",
    "df = pd.concat([con_df, pd_df], ignore_index=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. Clean column names\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df.columns = df.columns.str.strip().str.replace(\" \", \"_\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4. Extract Subject ID from filename\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_id(fname: str) -> str:\n",
    "    base = Path(fname).stem\n",
    "    m = re.search(r\"_[a-zA-Z]*([0-9]+)\", base)\n",
    "    return m.group(1) if m else base\n",
    "\n",
    "df[\"SubjectID\"] = df[\"File\"].apply(get_id)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5. Manually selected features\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "manual_features = [\n",
    "    \"Feature_asym_energy_content_below_05_Power_Spectrum_Density_AP\",\n",
    "    \"Feature_avg_frequency_quotient_Power_Spectrum_Density_ML\",\n",
    "    \"Feature_avg_fractal_dimension_ML_AND_AP\",\n",
    "    \"Feature_avg_phase_plane_parameter_ML\",\n",
    "    \"Feature_avg_short_time_diffusion_Diffusion_ML\",\n",
    "    \"Feature_asym_mean_distance_Radius\",\n",
    "    \"Height\",\n",
    "    \"Age\",\n",
    "    \"Weight\"\n",
    "]\n",
    "\n",
    "# Check availability\n",
    "available_features = [f for f in manual_features if f in df.columns]\n",
    "missing = set(manual_features) - set(available_features)\n",
    "if missing:\n",
    "    print(f\"âš ï¸ Warning: Missing features skipped: {missing}\")\n",
    "else:\n",
    "    print(\"âœ… All selected features are present.\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 6. Prepare feature matrix X\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if \"Sex\" in df.columns:\n",
    "    X = df[available_features + [\"Sex\"]].copy()\n",
    "    X = pd.get_dummies(X, columns=[\"Sex\"], drop_first=True)\n",
    "else:\n",
    "    X = df[available_features].copy()\n",
    "    print(\"âš ï¸ 'Sex' column not found. Proceeding without it.\")\n",
    "\n",
    "y = df[\"label\"].values\n",
    "groups = df[\"SubjectID\"].values\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 7. Cross-validation setup\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 8. Models and parameter grids\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "models = [\n",
    "    (\"SVM (RBF)\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(kernel=\"rbf\", probability=True, random_state=42))\n",
    "    ]), {\"clf__C\": [0.1, 1, 10], \"clf__gamma\": [\"scale\", 0.1]}),\n",
    "\n",
    "    (\"Random Forest\", Pipeline([\n",
    "        (\"clf\", RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "    ]), {\"clf__n_estimators\": [100], \"clf__max_depth\": [None]}),\n",
    "\n",
    "    (\"Logistic Regression\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=500, random_state=42))\n",
    "    ]), {\"clf__C\": [1]}),\n",
    "\n",
    "    (\"k-NN\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier())\n",
    "    ]), {\"clf__n_neighbors\": [5, 7]}),\n",
    "\n",
    "    (\"Gaussian NB\", Pipeline([\n",
    "        (\"clf\", GaussianNB())\n",
    "    ]), {})\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 9. Train, tune and evaluate\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for name, pipe, param_grid in models:\n",
    "    print(f\"\\nğŸ”¹ {name} Model ğŸ”¹\")\n",
    "    \n",
    "    # Grid Search CV\n",
    "    gs = GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1)\n",
    "    gs.fit(X, y, groups=groups)\n",
    "    best_est = gs.best_estimator_\n",
    "\n",
    "    # Evaluate with group-wise CV\n",
    "    accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "    for tr, te in cv.split(X, y, groups):\n",
    "        best_est.fit(X.iloc[tr], y[tr])\n",
    "        preds = best_est.predict(X.iloc[te])\n",
    "        probs = (best_est.predict_proba(X.iloc[te])[:, 1]\n",
    "                 if hasattr(best_est, \"predict_proba\")\n",
    "                 else best_est.decision_function(X.iloc[te]))\n",
    "\n",
    "        accs.append(accuracy_score(y[te], preds))\n",
    "        precs.append(precision_score(y[te], preds, zero_division=0))\n",
    "        recs.append(recall_score(y[te], preds, zero_division=0))\n",
    "        f1s.append(f1_score(y[te], preds, zero_division=0))\n",
    "        aucs.append(roc_auc_score(y[te], probs))\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Best Params: {gs.best_params_}\")\n",
    "    print(f\"Accuracy : {np.mean(accs):.3f} Â± {np.std(accs):.3f}\")\n",
    "    print(f\"Precision: {np.mean(precs):.3f} Â± {np.std(precs):.3f}\")\n",
    "    print(f\"Recall   : {np.mean(recs):.3f} Â± {np.std(recs):.3f}\")\n",
    "    print(f\"F1-score : {np.mean(f1s):.3f} Â± {np.std(f1s):.3f}\")\n",
    "    print(f\"ROC-AUC  : {np.mean(aucs):.3f} Â± {np.std(aucs):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503596b-ce42-453f-bfe2-e326ccea2b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
