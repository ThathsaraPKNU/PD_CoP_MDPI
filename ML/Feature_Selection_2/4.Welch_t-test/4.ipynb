{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd2a2e98-c493-483e-afa4-63e60be63974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 20 Most Significant Features (by ANOVA p-value) ===\n",
      "                                               Feature  Control_Mean  \\\n",
      "125  Feature_asym_energy_content_below_05_Power_Spe...      0.155235   \n",
      "26             Feature_avg_fractal_dimension_ML_AND_AP      2.773514   \n",
      "45   Feature_avg_power_frequency_95_Power_Spectrum_...      2.737618   \n",
      "121  Feature_asym_centroid_frequency_Power_Spectrum...      0.035792   \n",
      "44   Feature_avg_power_frequency_95_Power_Spectrum_...      2.758763   \n",
      "59   Feature_avg_frequency_quotient_Power_Spectrum_...      0.117110   \n",
      "117  Feature_asym_power_frequency_95_Power_Spectrum...      0.048024   \n",
      "49   Feature_avg_centroid_frequency_Power_Spectrum_...      1.278092   \n",
      "132     Feature_asym_short_time_diffusion_Diffusion_ML      0.061559   \n",
      "131  Feature_asym_frequency_quotient_Power_Spectrum...      0.140286   \n",
      "48   Feature_avg_centroid_frequency_Power_Spectrum_...      1.304404   \n",
      "52   Feature_avg_energy_content_below_05_Power_Spec...      0.196923   \n",
      "89      Feature_asym_confidence_ellipse_area_ML_AND_AP      0.070436   \n",
      "39                Feature_avg_mean_frequency_ML_AND_AP      0.986495   \n",
      "70         Feature_avg_short_time_scaling_Diffusion_AP      0.643050   \n",
      "25                           Feature_avg_LFS_ML_AND_AP    284.645549   \n",
      "81                                 Feature_asym_rms_AP      0.061321   \n",
      "139      Feature_asym_long_time_diffusion_Diffusion_AP      0.135713   \n",
      "141    Feature_asym_critical_displacement_Diffusion_AP      0.150286   \n",
      "97                          Feature_asym_LFS_ML_AND_AP      0.070353   \n",
      "\n",
      "        PD_Mean  Mean_Diff    ANOVA_F       ANOVA_p      T-test_p  \\\n",
      "125    0.299929   0.144694  31.335657  1.540732e-07  2.627739e-07   \n",
      "26     2.684808   0.088706  13.487722  3.684300e-04  2.589624e-04   \n",
      "45     2.532364   0.205254  13.170372  4.285920e-04  4.695817e-04   \n",
      "121    0.057725   0.021932  13.129269  4.370898e-04  5.331876e-04   \n",
      "44     2.627993   0.130770  11.932178  7.777300e-04  8.395314e-04   \n",
      "59     0.096759   0.020350  11.128672  1.150811e-03  1.075420e-03   \n",
      "117    0.074432   0.026409   9.979514  2.031046e-03  2.275854e-03   \n",
      "49     1.207945   0.070147   9.547813  2.520535e-03  2.784685e-03   \n",
      "132    0.093740   0.032182   9.409442  2.701983e-03  2.997834e-03   \n",
      "131    0.203884   0.063597   9.063658  3.216756e-03  3.567035e-03   \n",
      "48     1.253749   0.050654   8.015754  5.490890e-03  6.883644e-03   \n",
      "52     0.255979   0.059056   7.992932  5.555822e-03  8.858637e-03   \n",
      "89     0.102752   0.032316   7.753234  6.287865e-03  7.771458e-03   \n",
      "39     0.912700   0.073795   7.603380  6.795690e-03  6.719018e-03   \n",
      "70     0.664030   0.020981   6.536615  1.189387e-02  1.035459e-02   \n",
      "25   240.855280  43.790268   6.211284  1.414458e-02  1.093740e-02   \n",
      "81     0.090225   0.028904   6.034144  1.555309e-02  1.890795e-02   \n",
      "139    0.194184   0.058471   5.902507  1.669438e-02  1.869477e-02   \n",
      "141    0.209242   0.058956   5.889205  1.681448e-02  1.820837e-02   \n",
      "97     0.096200   0.025847   5.686854  1.875747e-02  2.125937e-02   \n",
      "\n",
      "         U-test_p  \n",
      "125  9.957808e-08  \n",
      "26   5.308363e-04  \n",
      "45   7.383716e-04  \n",
      "121  3.190092e-04  \n",
      "44   1.935279e-03  \n",
      "59   9.794355e-04  \n",
      "117  1.317201e-03  \n",
      "49   4.033175e-03  \n",
      "132  2.292293e-03  \n",
      "131  4.253504e-03  \n",
      "48   9.932202e-03  \n",
      "52   5.393934e-02  \n",
      "89   1.595884e-02  \n",
      "39   8.858774e-03  \n",
      "70   1.185398e-02  \n",
      "25   4.794891e-02  \n",
      "81   3.097702e-02  \n",
      "139  1.243234e-02  \n",
      "141  1.345194e-02  \n",
      "97   2.885792e-02  \n",
      "\n",
      "âœ… Results saved to 'significant_features_summary.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import f_classif\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. Load Control and PD data\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "con_df = pd.read_csv(r\"E:\\USA_PD_2024\\Analysis\\ppr6\\COP\\ML\\Feature_Selection_2\\Data\\Controlled1.csv\")\n",
    "pd_df  = pd.read_csv(r\"E:\\USA_PD_2024\\Analysis\\ppr6\\COP\\ML\\Feature_Selection_2\\Data\\PD1.csv\")\n",
    "\n",
    "# Strip column names (important)\n",
    "con_df.columns = con_df.columns.str.strip()\n",
    "pd_df.columns  = pd_df.columns.str.strip()\n",
    "\n",
    "# Add label column\n",
    "con_df[\"label\"] = 0\n",
    "pd_df[\"label\"] = 1\n",
    "\n",
    "# Combine into one DataFrame\n",
    "df = pd.concat([con_df, pd_df], ignore_index=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. Preprocess: Drop meta-columns\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "drop_cols = [\"label\", \"File\"]  # Demographics already removed\n",
    "X = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "y = df[\"label\"].values  # 0 = Control, 1 = PD\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. Run per-feature statistical tests\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "results = []\n",
    "\n",
    "for col in X.columns:\n",
    "    ctrl_vals = X[y == 0][col]\n",
    "    pd_vals   = X[y == 1][col]\n",
    "\n",
    "    # Welch's t-test (unequal variance)\n",
    "    t_stat, t_pval = ttest_ind(ctrl_vals, pd_vals, equal_var=False)\n",
    "\n",
    "    # Mannâ€“Whitney U test\n",
    "    u_stat, u_pval = mannwhitneyu(ctrl_vals, pd_vals, alternative=\"two-sided\")\n",
    "\n",
    "    results.append({\n",
    "        \"Feature\": col,\n",
    "        \"Control_Mean\": np.mean(ctrl_vals),\n",
    "        \"PD_Mean\": np.mean(pd_vals),\n",
    "        \"T-test_p\": t_pval,\n",
    "        \"U-test_p\": u_pval,\n",
    "        \"Mean_Diff\": abs(np.mean(ctrl_vals) - np.mean(pd_vals))\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "res_df = pd.DataFrame(results)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4. Add ANOVA F-test and p-values\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "f_vals, f_pvals = f_classif(X, y)\n",
    "res_df[\"ANOVA_F\"] = f_vals\n",
    "res_df[\"ANOVA_p\"] = f_pvals\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5. Add significance flags and sort\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "res_df[\"p<0.05\"] = res_df[\"ANOVA_p\"] < 0.05\n",
    "res_df[\"p<0.01\"] = res_df[\"ANOVA_p\"] < 0.01\n",
    "\n",
    "res_df = res_df.sort_values(\"ANOVA_p\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 6. Show and Save Results\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Show top 20 most significant features\n",
    "print(\"\\n=== Top 20 Most Significant Features (by ANOVA p-value) ===\")\n",
    "print(res_df[[\"Feature\", \"Control_Mean\", \"PD_Mean\", \"Mean_Diff\", \"ANOVA_F\", \"ANOVA_p\", \"T-test_p\", \"U-test_p\"]].head(20))\n",
    "\n",
    "# Save all results\n",
    "res_df.to_csv(\"significant_features_summary.csv\", index=False)\n",
    "print(\"\\nâœ… Results saved to 'significant_features_summary.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade013da-a3d1-4e52-928f-e2f7a3a86e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All selected features are present.\n",
      "âš ï¸ 'Sex' column not found. Proceeding without it.\n",
      "\n",
      "ğŸ”¹ SVM (RBF) Model ğŸ”¹\n",
      "Best Params: {'clf__C': 1, 'clf__gamma': 0.1}\n",
      "Accuracy : 0.713 Â± 0.098\n",
      "Precision: 0.716 Â± 0.149\n",
      "Recall   : 0.700 Â± 0.132\n",
      "F1-score : 0.692 Â± 0.090\n",
      "ROC-AUC  : 0.798 Â± 0.091\n",
      "\n",
      "ğŸ”¹ Random Forest Model ğŸ”¹\n",
      "Best Params: {'clf__max_depth': None, 'clf__n_estimators': 100}\n",
      "Accuracy : 0.748 Â± 0.093\n",
      "Precision: 0.751 Â± 0.151\n",
      "Recall   : 0.760 Â± 0.109\n",
      "F1-score : 0.740 Â± 0.076\n",
      "ROC-AUC  : 0.823 Â± 0.108\n",
      "\n",
      "ğŸ”¹ Logistic Regression Model ğŸ”¹\n",
      "Best Params: {'clf__C': 1}\n",
      "Accuracy : 0.791 Â± 0.051\n",
      "Precision: 0.782 Â± 0.126\n",
      "Recall   : 0.795 Â± 0.077\n",
      "F1-score : 0.778 Â± 0.047\n",
      "ROC-AUC  : 0.856 Â± 0.092\n",
      "\n",
      "ğŸ”¹ k-NN Model ğŸ”¹\n",
      "Best Params: {'clf__n_neighbors': 5}\n",
      "Accuracy : 0.696 Â± 0.087\n",
      "Precision: 0.683 Â± 0.097\n",
      "Recall   : 0.665 Â± 0.138\n",
      "F1-score : 0.665 Â± 0.093\n",
      "ROC-AUC  : 0.739 Â± 0.077\n",
      "\n",
      "ğŸ”¹ Gaussian NB Model ğŸ”¹\n",
      "Best Params: {}\n",
      "Accuracy : 0.748 Â± 0.080\n",
      "Precision: 0.756 Â± 0.128\n",
      "Recall   : 0.720 Â± 0.084\n",
      "F1-score : 0.727 Â± 0.068\n",
      "ROC-AUC  : 0.803 Â± 0.122\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Binary PD vs Control classification using manually selected CoP + demographic features\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Features: 15 CoP-derived + Height, Weight, Sex (if available)\n",
    "Modeling: SVM, RF, LR, k-NN, GNB\n",
    "Validation: 5-fold GroupKFold using SubjectID\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. Imports\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. Load and concatenate data\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "con_df = pd.read_csv(r\"E:\\USA_PD_2024\\Analysis\\ppr6\\COP\\ML\\Feature_Selection_2\\Data\\Controlled1.csv\")\n",
    "pd_df  = pd.read_csv(r\"E:\\USA_PD_2024\\Analysis\\ppr6\\COP\\ML\\Feature_Selection_2\\Data\\PD1.csv\")\n",
    "\n",
    "con_df[\"label\"] = 0\n",
    "pd_df [\"label\"] = 1\n",
    "df = pd.concat([con_df, pd_df], ignore_index=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. Clean column names\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df.columns = df.columns.str.strip().str.replace(\" \", \"_\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4. Extract Subject ID from filename\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_id(fname: str) -> str:\n",
    "    base = Path(fname).stem\n",
    "    m = re.search(r\"_[a-zA-Z]*([0-9]+)\", base)\n",
    "    return m.group(1) if m else base\n",
    "\n",
    "df[\"SubjectID\"] = df[\"File\"].apply(get_id)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5. Manually selected features\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "manual_features = [\n",
    "    \"Feature_asym_energy_content_below_05_Power_Spectrum_Density_AP\",\n",
    "    \"Feature_avg_fractal_dimension_ML_AND_AP\",\n",
    "    \"Feature_avg_power_frequency_95_Power_Spectrum_Density_AP\",\n",
    "    \"Feature_asym_centroid_frequency_Power_Spectrum_Density_AP\",\n",
    "    \"Feature_avg_power_frequency_95_Power_Spectrum_Density_ML\",\n",
    "    \"Feature_avg_frequency_quotient_Power_Spectrum_Density_AP\",\n",
    "    \"Feature_asym_power_frequency_95_Power_Spectrum_Density_AP\",\n",
    "    \"Feature_avg_centroid_frequency_Power_Spectrum_Density_AP\",\n",
    "    \"Feature_asym_short_time_diffusion_Diffusion_ML\",\n",
    "    \"Feature_asym_frequency_quotient_Power_Spectrum_Density_AP\",\n",
    "    \"Feature_avg_centroid_frequency_Power_Spectrum_Density_ML\",\n",
    "    \"Feature_avg_energy_content_below_05_Power_Spectrum_Density_ML\",\n",
    "    \"Feature_asym_confidence_ellipse_area_ML_AND_AP\",\n",
    "    \"Feature_avg_mean_frequency_ML_AND_AP\",\n",
    "    \"Feature_avg_short_time_scaling_Diffusion_AP\",\n",
    "    \"Feature_avg_LFS_ML_AND_AP\",\n",
    "    \"Feature_asym_rms_AP\",\n",
    "    \"Feature_asym_long_time_diffusion_Diffusion_AP\",\n",
    "    \"Feature_asym_critical_displacement_Diffusion_AP\",\n",
    "    \"Feature_asym_LFS_ML_AND_AP\"\n",
    "]\n",
    "\n",
    "# Check availability\n",
    "available_features = [f for f in manual_features if f in df.columns]\n",
    "missing = set(manual_features) - set(available_features)\n",
    "if missing:\n",
    "    print(f\"âš ï¸ Warning: Missing features skipped: {missing}\")\n",
    "else:\n",
    "    print(\"âœ… All selected features are present.\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 6. Prepare feature matrix X\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if \"Sex\" in df.columns:\n",
    "    X = df[available_features + [\"Sex\"]].copy()\n",
    "    X = pd.get_dummies(X, columns=[\"Sex\"], drop_first=True)\n",
    "else:\n",
    "    X = df[available_features].copy()\n",
    "    print(\"âš ï¸ 'Sex' column not found. Proceeding without it.\")\n",
    "\n",
    "y = df[\"label\"].values\n",
    "groups = df[\"SubjectID\"].values\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 7. Cross-validation setup\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 8. Models and parameter grids\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "models = [\n",
    "    (\"SVM (RBF)\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(kernel=\"rbf\", probability=True, random_state=42))\n",
    "    ]), {\"clf__C\": [0.1, 1, 10], \"clf__gamma\": [\"scale\", 0.1]}),\n",
    "\n",
    "    (\"Random Forest\", Pipeline([\n",
    "        (\"clf\", RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "    ]), {\"clf__n_estimators\": [100], \"clf__max_depth\": [None]}),\n",
    "\n",
    "    (\"Logistic Regression\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=500, random_state=42))\n",
    "    ]), {\"clf__C\": [1]}),\n",
    "\n",
    "    (\"k-NN\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier())\n",
    "    ]), {\"clf__n_neighbors\": [5, 7]}),\n",
    "\n",
    "    (\"Gaussian NB\", Pipeline([\n",
    "        (\"clf\", GaussianNB())\n",
    "    ]), {})\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 9. Train, tune and evaluate\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for name, pipe, param_grid in models:\n",
    "    print(f\"\\nğŸ”¹ {name} Model ğŸ”¹\")\n",
    "    \n",
    "    # Grid Search CV\n",
    "    gs = GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1)\n",
    "    gs.fit(X, y, groups=groups)\n",
    "    best_est = gs.best_estimator_\n",
    "\n",
    "    # Evaluate with group-wise CV\n",
    "    accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "    for tr, te in cv.split(X, y, groups):\n",
    "        best_est.fit(X.iloc[tr], y[tr])\n",
    "        preds = best_est.predict(X.iloc[te])\n",
    "        probs = (best_est.predict_proba(X.iloc[te])[:, 1]\n",
    "                 if hasattr(best_est, \"predict_proba\")\n",
    "                 else best_est.decision_function(X.iloc[te]))\n",
    "\n",
    "        accs.append(accuracy_score(y[te], preds))\n",
    "        precs.append(precision_score(y[te], preds, zero_division=0))\n",
    "        recs.append(recall_score(y[te], preds, zero_division=0))\n",
    "        f1s.append(f1_score(y[te], preds, zero_division=0))\n",
    "        aucs.append(roc_auc_score(y[te], probs))\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Best Params: {gs.best_params_}\")\n",
    "    print(f\"Accuracy : {np.mean(accs):.3f} Â± {np.std(accs):.3f}\")\n",
    "    print(f\"Precision: {np.mean(precs):.3f} Â± {np.std(precs):.3f}\")\n",
    "    print(f\"Recall   : {np.mean(recs):.3f} Â± {np.std(recs):.3f}\")\n",
    "    print(f\"F1-score : {np.mean(f1s):.3f} Â± {np.std(f1s):.3f}\")\n",
    "    print(f\"ROC-AUC  : {np.mean(aucs):.3f} Â± {np.std(aucs):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e35c9-8f77-4666-a58f-cdb7227094a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
